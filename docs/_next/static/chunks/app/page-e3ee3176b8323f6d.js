(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[931],{7834:function(e,a,s){Promise.resolve().then(s.bind(s,2433))},2433:function(e,a,s){"use strict";s.r(a),s.d(a,{default:function(){return A}});var t=s(7437),i=s(7648);function n(){return(0,t.jsx)("footer",{className:"anime-footer",children:(0,t.jsxs)("div",{className:"section-container flex flex-col gap-8 py-12 md:flex-row md:items-center md:justify-between text-[var(--text-dark)]",children:[(0,t.jsxs)("div",{children:[(0,t.jsxs)("div",{className:"flex items-center gap-3",children:[(0,t.jsx)("div",{className:"brand-symbol text-4xl leading-none",children:"π"}),(0,t.jsx)("p",{className:"font-display text-lg text-[var(--text-dark)]",children:"ReinforceLab"})]}),(0,t.jsxs)("p",{className:"mt-3 text-xs text-[var(--text-dark)]",children:["Adaptive intelligence for every workflow. \xa9 ",new Date().getFullYear(),"."]})]}),(0,t.jsxs)("nav",{className:"flex flex-wrap gap-4 text-sm text-[var(--text-dark)]",children:[(0,t.jsx)(i.default,{href:"/privacy",children:"Privacy"}),(0,t.jsx)(i.default,{href:"/api-docs",children:"API Docs"}),(0,t.jsx)(i.default,{href:"/careers",children:"Careers"}),(0,t.jsx)("a",{href:"mailto:hello@reinforcelab.ai",children:"hello@reinforcelab.ai"})]})]})})}let r={hidden:{opacity:0,y:24},visible:{opacity:1,y:0,transition:{duration:.6,ease:"easeOut"}}},l={hidden:{},visible:{transition:{staggerChildren:.12}}},c={once:!0,amount:.2};var o=s(3810);function d(){return(0,t.jsx)("section",{id:"about",className:"anime-section section-container",children:(0,t.jsxs)(o.E.div,{initial:"hidden",whileInView:"visible",viewport:c,variants:l,className:"grid gap-10 lg:grid-cols-2",children:[(0,t.jsxs)(o.E.div,{variants:r,className:"space-y-5",children:[(0,t.jsx)("span",{className:"text-sm font-semibold uppercase tracking-[0.3em] text-[var(--flat-lime)]",children:"About ReinforceLab"}),(0,t.jsx)("h2",{className:"section-title",children:"Mission: Translate reward signals into durable, auditable, high-impact business value."}),(0,t.jsx)("div",{className:"title-underline","aria-hidden":"true"}),(0,t.jsx)("p",{className:"text-white/70",children:"ReinforceLab bridges the gap between cutting-edge RL research and enterprise deployment. We align cross-functional teams around adaptive intelligence programs that deliver measurable results across strategy, simulation, policy deployment, and ongoing governance."})]}),(0,t.jsxs)(o.E.div,{variants:r,className:"glass-panel rounded-3xl p-6 text-sm text-white/70",children:[(0,t.jsx)("p",{children:"Our teams combine RL scientists, systems engineers, and AgentOps specialists who design transparent, evolving, and regulation-ready adaptive systems. We build learning pipelines your teams can inherit, understand, and trust."}),(0,t.jsx)("p",{className:"mt-4",children:"Vision: Make continuous learning a scalable, managed capability for every enterprise—explainable, ethical, and economically aligned with every decision maker."})]})]})})}function m(){return(0,t.jsxs)("section",{id:"contact",className:"anime-contact section-container",children:[(0,t.jsxs)(o.E.div,{initial:"hidden",whileInView:"visible",viewport:c,variants:l,className:"mx-auto max-w-3xl text-center",children:[(0,t.jsx)(o.E.span,{variants:r,className:"text-sm font-semibold uppercase tracking-[0.3em] text-[var(--flat-lime)]",children:"Contact"}),(0,t.jsx)(o.E.h2,{variants:r,className:"section-title mt-4",children:"Request a Demo"}),(0,t.jsx)("div",{className:"title-underline","aria-hidden":"true"}),(0,t.jsx)(o.E.p,{variants:r,className:"mt-4 text-white/70",children:"Share your use case and we'll map the reinforcement learning motion that accelerates results—from KPI design to production deployment."})]}),(0,t.jsxs)(o.E.form,{variants:l,initial:"hidden",whileInView:"visible",viewport:c,className:"mt-12 glass-panel mx-auto max-w-3xl space-y-6 rounded-3xl p-8 text-left",children:[(0,t.jsxs)("div",{className:"grid gap-6 md:grid-cols-2",children:[(0,t.jsxs)(o.E.label,{variants:r,className:"space-y-2 text-sm",children:[(0,t.jsx)("span",{className:"text-white/70",children:"Full Name"}),(0,t.jsx)("input",{type:"text",required:!0,placeholder:"Alex Morgan",className:"w-full rounded-2xl border border-white/10 bg-[var(--input-fill)] px-4 py-3 text-[var(--text-dark)] placeholder:text-[rgba(232,236,245,0.7)] focus:border-[var(--pale-yellow)] focus:outline-none"})]}),(0,t.jsxs)(o.E.label,{variants:r,className:"space-y-2 text-sm",children:[(0,t.jsx)("span",{className:"text-white/70",children:"Work Email"}),(0,t.jsx)("input",{type:"email",required:!0,placeholder:"alex@enterprise.ai",className:"w-full rounded-2xl border border-white/10 bg-[var(--input-fill)] px-4 py-3 text-[var(--text-dark)] placeholder:text-[rgba(232,236,245,0.7)] focus:border-[var(--pale-yellow)] focus:outline-none"})]})]}),(0,t.jsxs)(o.E.label,{variants:r,className:"space-y-2 text-sm",children:[(0,t.jsx)("span",{className:"text-white/70",children:"Company"}),(0,t.jsx)("input",{type:"text",required:!0,placeholder:"ReinforceLab",className:"w-full rounded-2xl border border-white/10 bg-[var(--input-fill)] px-4 py-3 text-[var(--text-dark)] placeholder:text-[rgba(232,236,245,0.7)] focus:border-[var(--pale-yellow)] focus:outline-none"})]}),(0,t.jsxs)(o.E.label,{variants:r,className:"space-y-2 text-sm",children:[(0,t.jsx)("span",{className:"text-white/70",children:"Primary Objective"}),(0,t.jsxs)("select",{required:!0,className:"w-full appearance-none rounded-2xl border border-white/10 bg-[var(--input-fill)] px-4 py-3 text-[var(--text-dark)] focus:border-[var(--pale-yellow)] focus:outline-none",children:[(0,t.jsx)("option",{className:"text-[var(--text-dark)]",children:"Adaptive pricing & revenue"}),(0,t.jsx)("option",{className:"text-[var(--text-dark)]",children:"Operational optimization & automation"}),(0,t.jsx)("option",{className:"text-[var(--text-dark)]",children:"Personalized engagement & marketing"}),(0,t.jsx)("option",{className:"text-[var(--text-dark)]",children:"RL research partnership / co-development"}),(0,t.jsx)("option",{className:"text-[var(--text-dark)]",children:"Other (include details below)"})]})]}),(0,t.jsxs)(o.E.label,{variants:r,className:"space-y-2 text-sm",children:[(0,t.jsx)("span",{className:"text-white/70",children:"How can we help?"}),(0,t.jsx)("textarea",{rows:4,placeholder:"Tell us about your current AI strategy, data sources, and success metrics.",className:"w-full rounded-2xl border border-white/10 bg-[var(--input-fill)] px-4 py-3 text-[var(--text-dark)] placeholder:text-[rgba(232,236,245,0.7)] focus:border-[var(--pale-yellow)] focus:outline-none"})]}),(0,t.jsx)(o.E.button,{variants:r,type:"submit",className:"anime-btn w-full rounded-full px-6 py-3 text-sm font-semibold",children:"Submit Request"})]})]})}let h=[{title:"Tailored Learning Environments",description:"Domain-specific simulators let agents explore safely before production."},{title:"Actively Learning AI Agents",description:"Policies evolve in real time based on fresh feedback loops."},{title:"Simulation-First Experimentation",description:"Stress test strategies, analyze edge cases, and surface emergent behavior at scale."},{title:"Adaptive Decision Systems",description:"Evolve from static LLM workflows to continuous-learning pipelines that deliver measurable outcomes."}],p=[{name:"Adaptive Intelligence Consulting",summary:"Translate business objectives into RL frameworks and experimentation roadmaps.",details:["Translate business objectives into RL frameworks and experimentation roadmaps.","Align KPIs with reward design and long-term strategic impact.","Identify automation opportunities and define ROI metrics.","Connect data science and operations into unified adaptive workflows."]},{name:"Simulation Environment Design",summary:"Build synthetic environments that de-risk policy learning.",details:["Build synthetic environments that de-risk policy learning.","Model multi-agent dynamics, rare events, and complex feedback loops.","Accelerate policy robustness via controlled experiments.","Deploy cloud or edge simulators with observability built-in."]},{name:"Policy Learning & Optimization",summary:"Engineer adaptive policies for volatile, high-variance environments.",details:["Apply bandits, DQN, actor-critic methods, and continual learning.","Shape rewards to reflect constraints and maintain exploration balance.","Benchmark across simulation and production with safety gates."]},{name:"RL Integration & Deployment",summary:"Embed decision layers within CRM, ERP, and workflow systems.",details:["Provide secure policy APIs with runtime guardrails.","Enable low-latency inference, CI/CD retraining, and observability.","Align fully with existing data ecosystems."]},{name:"Managed RL-as-a-Service",summary:"Full RL operations with outcome-based SLAs.",details:["Multi-agent workload support at scale.","Automated evaluation, drift correction, versioning, and rollouts.","Continuous retraining based on live feedback signals."]},{name:"Analytics & Governance",summary:"Executive-ready transparency into adaptive systems.",details:["Interpretability reports, fairness audits, and ROI tracking.","Governance dashboards for compliance, ethics, and real-world impact.","Continuous monitoring to reinforce trust and alignment."]}],u=[{name:"Adaptive Recommendation Engine",summary:"Ensemble bandits + hierarchical clustering for in-the-moment personalization.",details:["Learns from user behavior and context in real time.","Balances exploration, conversion, and trend sensitivity.","Plugs into e-commerce and media systems."]},{name:"Dynamic Pricing & Demand Optimization",summary:"RL-driven real-time pricing adjustments.",details:["Models elasticity, competition, and seasonality.","Continuous contextual experimentation under safety controls.","Tuned for retail, SaaS, and travel."]},{name:"Operational Workflow Optimizer",summary:"Agents that streamline operations by learning from every task.",details:["Automates routing, scheduling, and resource allocation.","Predicts delays and rebalances workloads.","Integrates with logistics and ERP systems."]},{name:"Personalized Engagement Engine",summary:"Campaigns that self-tune based on reward signals.",details:["Optimizes cadence, channel, tone, and sequencing.","Learns across the customer journey.","Connects to CRM and marketing automation stacks."]},{name:"Resource Allocation & Simulation Suite",summary:"Multi-agent simulation for fleets, supply chains, and infrastructure.",details:["Stress tests, rare event modeling, and sensitivity analyses.","Sensor-driven real-time coordination logic.","APIs and dashboards for operations teams."]},{name:"Decision Intelligence Dashboard",summary:"Full transparency into every policy decision.",details:["Reward curves, drift charts, governance metrics.","Built-in explainability and compliance reporting.","Automates oversight with auditable outputs."]}],x=[{name:"RLX Leaderboards",description:"Benchmark agents on exploration, generalization, and safety metrics with transparent scorecards."},{name:"Self-Reflective Learning (SRL)",description:"Teach agents to audit their own trajectories, revise strategies, and document reasoning trails."},{name:"Meta-Ethical Reward Shaping",description:"Align policies with nuanced cultural and human values via value-sensitive reward engineering."},{name:"Safe-RL Protocols",description:"Engineer verifiably robust policies for high-risk domains with formal safeguards."}],v=[{label:"AgentOps Observability",stat:"45+",description:"prebuilt monitors track policy drift, fairness, governance, and ROI in flight."},{label:"Agentic Guardrails",stat:"Zero-Trust",description:"alignment controls, safety throttles, and runtime prevention for harmful actions."},{label:"ROI Realization",stat:"8-12 mo",description:"time to measurable uplift across pricing, operations, logistics, and engagement programs."}];function g(){return(0,t.jsxs)("section",{id:"hero",className:"anime-hero section-container flex flex-col gap-12 pb-24 pt-16 lg:flex-row lg:items-center lg:gap-16 lg:pt-28",children:[(0,t.jsxs)(o.E.div,{variants:l,initial:"hidden",animate:"visible",className:"w-full lg:w-1/2",children:[(0,t.jsx)(o.E.span,{variants:r,className:"inline-flex items-center gap-2 rounded-full border border-white/10 bg-white/5 px-4 py-1 text-xs uppercase tracking-[0.2em] text-white/70",children:"ReinforceLab"}),(0,t.jsx)(o.E.h1,{variants:r,className:"mt-6 font-display text-4xl leading-tight text-white md:text-5xl lg:text-6xl",children:"From Rewards to Reality — Reinforcement Learning That Scales."}),(0,t.jsx)(o.E.p,{variants:r,className:"mt-2 text-lg font-semibold text-[var(--flat-lime)]",children:"Agentic Guardrails for every adaptive decision."}),(0,t.jsx)(o.E.p,{variants:r,className:"mt-6 text-lg text-white/80",children:"ReinforceLab empowers enterprises with adaptive, goal-driven AI systems that continuously learn from interaction, feedback, and outcomes. We convert reward signals into tangible business impact across pricing, operations, logistics, and engagement programs."}),(0,t.jsxs)(o.E.div,{variants:r,className:"mt-10 flex flex-wrap items-center gap-4",children:[(0,t.jsx)("a",{href:"#contact",className:"anime-btn rounded-full px-6 py-3 text-sm font-semibold",children:"Request a Demo"}),(0,t.jsx)("a",{href:"#services",className:"anime-btn rounded-full border px-6 py-3 text-sm font-semibold",children:"Explore Services"})]})]}),(0,t.jsx)(o.E.div,{initial:{opacity:0,scale:.96},animate:{opacity:1,scale:1},transition:{duration:.8,ease:"easeOut",delay:.2},className:"w-full lg:w-1/2",children:(0,t.jsx)("div",{className:"anime-metrics glass-panel relative overflow-hidden rounded-3xl p-0",children:(0,t.jsx)("div",{className:"hero-roller",children:(0,t.jsx)("div",{className:"hero-roller-track",children:[...v,...v].map((e,a)=>(0,t.jsxs)("div",{className:"metric-card anime-card p-5",children:[(0,t.jsx)("p",{className:"metric-label text-xs uppercase tracking-[0.2em]",children:e.label}),(0,t.jsx)("p",{className:"metric-stat mt-2 text-2xl font-semibold",children:e.stat}),(0,t.jsx)("p",{className:"metric-copy mt-2 text-xs",children:e.description})]},"".concat(e.label,"-").concat(a)))})})})})]})}function f(){return(0,t.jsx)("header",{className:"anime-header-notch",children:(0,t.jsxs)("div",{className:"nav-notch",children:[(0,t.jsx)("div",{className:"nav-left",children:(0,t.jsxs)("span",{className:"nav-logo",children:[(0,t.jsx)("span",{className:"brand-symbol nav-pi",children:"π"}),(0,t.jsx)("span",{className:"nav-logo-text",children:"ReinforceLab"})]})}),(0,t.jsxs)("nav",{className:"nav-links",children:[(0,t.jsx)("a",{href:"#services",children:"Services"}),(0,t.jsx)("a",{href:"#solutions",children:"Solutions"}),(0,t.jsx)("a",{href:"#research",children:"Research"}),(0,t.jsx)("a",{href:"#about",children:"About"}),(0,t.jsx)("a",{href:"#contact",children:"Contact"})]}),(0,t.jsxs)("div",{className:"nav-right",children:[(0,t.jsx)("button",{className:"demo-btn",children:"Request a Demo"}),(0,t.jsx)("button",{className:"hamburger","aria-label":"Open navigation menu",children:"≡"})]})]})})}function b(){return(0,t.jsxs)("section",{id:"research",className:"anime-section research section-container",children:[(0,t.jsxs)(o.E.div,{initial:"hidden",whileInView:"visible",viewport:c,variants:l,className:"mx-auto max-w-3xl text-center",children:[(0,t.jsx)(o.E.span,{variants:r,className:"text-sm font-semibold uppercase tracking-[0.3em] text-[var(--flat-lime)]",children:"RL Frontier Research"}),(0,t.jsx)(o.E.h2,{variants:r,className:"section-title mt-4",children:"Shaping the Next Wave of Adaptive Intelligence"}),(0,t.jsx)("div",{className:"title-underline","aria-hidden":"true"}),(0,t.jsx)(o.E.p,{variants:r,className:"mt-4 text-white/70",children:"ReinforceLab invests in frameworks that push the boundaries of performance, safety, and cultural alignment so every deployment stays benchmarked, introspective, and responsible."})]}),(0,t.jsx)(o.E.div,{variants:l,initial:"hidden",whileInView:"visible",viewport:c,className:"mt-14 grid gap-6 md:grid-cols-2",children:x.map(e=>(0,t.jsxs)(o.E.div,{variants:r,className:"anime-card anime-card-green glass-panel rounded-2xl p-6",children:[(0,t.jsx)("h3",{className:"font-display text-xl text-white",children:e.name}),(0,t.jsx)("p",{className:"mt-3 text-sm text-white/70",children:e.description})]},e.name))})]})}function y(){return(0,t.jsxs)("section",{id:"services",className:"section-container",children:[(0,t.jsxs)(o.E.div,{initial:"hidden",whileInView:"visible",viewport:c,variants:l,className:"mx-auto max-w-3xl text-center",children:[(0,t.jsx)(o.E.span,{variants:r,className:"text-sm font-semibold uppercase tracking-[0.3em] text-[var(--flat-lime)]",children:"Services"}),(0,t.jsx)(o.E.h2,{variants:r,className:"section-title mt-4",children:"Reinforcement Learning, Delivered End-to-End"}),(0,t.jsx)("div",{className:"title-underline","aria-hidden":"true"}),(0,t.jsx)(o.E.p,{variants:r,className:"mt-4 text-white/70",children:"Our six-part service suite spans strategy, simulation, policy engineering, deployment, operations, and governance—designed to move engagements from proof-of-value to production-grade impact."})]}),(0,t.jsx)(o.E.div,{variants:l,initial:"hidden",whileInView:"visible",viewport:c,className:"mt-16 grid gap-6 lg:grid-cols-3",children:p.map(e=>(0,t.jsxs)(o.E.article,{variants:r,whileHover:{y:-8,scale:1.02},className:"anime-card anime-card-green glass-panel flex h-full flex-col rounded-lg p-6",children:[(0,t.jsx)("div",{className:"flex items-center gap-3",children:(0,t.jsx)("h3",{className:"font-display text-lg",children:e.name})}),(0,t.jsx)("p",{className:"mt-4 text-sm",children:e.summary}),(0,t.jsx)("ul",{className:"mt-5 space-y-3 text-sm",children:e.details.map(e=>(0,t.jsxs)("li",{className:"flex items-start gap-2",children:[(0,t.jsx)("span",{className:"mt-1 h-1.5 w-1.5 rounded-full bg-[var(--green-border)]"}),(0,t.jsx)("span",{children:e})]},e))})]},e.name))})]})}function j(){return(0,t.jsxs)("section",{id:"solutions",className:"anime-section solutions section-container",children:[(0,t.jsxs)(o.E.div,{initial:"hidden",whileInView:"visible",viewport:c,variants:l,className:"mx-auto max-w-3xl text-center",children:[(0,t.jsx)(o.E.span,{variants:r,className:"text-sm font-semibold uppercase tracking-[0.3em] text-[var(--flat-lime)]",children:"Solutions"}),(0,t.jsx)(o.E.h2,{variants:r,className:"section-title mt-4",children:"Built-for-Impact RL Solution Gallery"}),(0,t.jsx)("div",{className:"title-underline","aria-hidden":"true"}),(0,t.jsx)(o.E.p,{variants:r,className:"mt-4 text-white/70",children:"Each solution ships with embedded measurement, governance, and Agentic Guardrails to jumpstart production impact across growth, operations, and intelligence workloads."})]}),(0,t.jsx)(o.E.div,{variants:l,initial:"hidden",whileInView:"visible",viewport:c,className:"mt-14 grid gap-6 md:grid-cols-2 lg:grid-cols-3",children:u.map(e=>(0,t.jsx)(o.E.div,{variants:r,whileHover:{y:-10,scale:1.02},className:"anime-card anime-card-green relative overflow-hidden rounded-2xl p-6 transition",children:(0,t.jsxs)("div",{className:"relative",children:[(0,t.jsx)("div",{className:"flex items-center gap-3",children:(0,t.jsx)("h3",{className:"font-display text-lg",children:e.name})}),(0,t.jsx)("p",{className:"mt-4 text-sm",children:e.summary}),(0,t.jsx)("ul",{className:"mt-5 space-y-3 text-sm",children:e.details.map(e=>(0,t.jsxs)("li",{className:"flex items-start gap-2",children:[(0,t.jsx)("span",{className:"mt-1 h-1.5 w-1.5 rounded-full bg-[var(--green-border)]"}),(0,t.jsx)("span",{children:e})]},e))})]})},e.name))})]})}function w(){return(0,t.jsx)("section",{id:"why-choose",className:"anime-section features section-container",children:(0,t.jsx)(o.E.div,{initial:"hidden",whileInView:"visible",viewport:c,variants:l,className:"grid gap-12",children:(0,t.jsxs)(o.E.div,{variants:r,className:"space-y-5",children:[(0,t.jsx)("span",{className:"text-sm font-semibold uppercase tracking-[0.3em] text-[var(--flat-lime)]",children:"Why Choose ReinforceLab"}),(0,t.jsx)("h2",{className:"section-title",children:"Agentic Guardrails with measurable impact."}),(0,t.jsx)("div",{className:"title-underline","aria-hidden":"true"}),(0,t.jsx)("p",{className:"text-white/70",children:"The next generation of adaptive intelligence requires more than clever policies—it needs Agentic Guardrails that ensure safety, alignment, and reliability across the entire decision lifecycle."}),(0,t.jsxs)("ul",{className:"space-y-3 text-sm text-white/70",children:[(0,t.jsxs)("li",{className:"flex gap-3",children:[(0,t.jsx)("span",{className:"h-2.5 w-2.5 translate-y-2 rounded-full bg-brand-indigo"}),"AgentOps observability with 45+ prebuilt monitors."]}),(0,t.jsxs)("li",{className:"flex gap-3",children:[(0,t.jsx)("span",{className:"h-2.5 w-2.5 translate-y-2 rounded-full bg-brand-teal"}),"Agentic Guardrails that enforce alignment and prevent harmful actions."]}),(0,t.jsxs)("li",{className:"flex gap-3",children:[(0,t.jsx)("span",{className:"h-2.5 w-2.5 translate-y-2 rounded-full bg-brand-sky"}),"Reward shaping, safety throttles, and human feedback loops for evolving constraints."]}),(0,t.jsxs)("li",{className:"flex gap-3",children:[(0,t.jsx)("span",{className:"h-2.5 w-2.5 translate-y-2 rounded-full bg-white/70"}),"Leadership-ready dashboards showing fairness, drift, and ROI metrics."]})]})]})})})}function N(){return(0,t.jsxs)("section",{id:"why-rl",className:"anime-section section-container",children:[(0,t.jsxs)(o.E.div,{className:"mx-auto max-w-3xl text-center",initial:"hidden",whileInView:"visible",viewport:c,variants:l,children:[(0,t.jsx)(o.E.span,{variants:r,className:"text-sm font-semibold uppercase tracking-[0.3em] text-[var(--flat-lime)]",children:"Beyond Conventional AI Pipelines"}),(0,t.jsx)(o.E.h2,{variants:r,className:"section-title mt-4",children:"Why Reinforcement Learning Now"}),(0,t.jsx)("div",{className:"title-underline","aria-hidden":"true"}),(0,t.jsx)(o.E.p,{variants:r,className:"mt-4 text-white/70",children:"Static prompts, fine-tunes, and retrospective analytics can't keep pace with dynamic markets. ReinforceLab builds adaptive systems that experiment, learn, and improve with every decision cycle—keeping your enterprise responsive, resilient, and ahead."})]}),(0,t.jsx)(o.E.div,{variants:l,initial:"hidden",whileInView:"visible",viewport:c,className:"mt-14 grid gap-6 md:grid-cols-2",children:h.map(e=>(0,t.jsxs)(o.E.div,{variants:r,whileHover:{y:-6,scale:1.02},className:"glass-panel h-full rounded-3xl p-6",children:[(0,t.jsx)("h3",{className:"font-display text-xl text-white",children:e.title}),(0,t.jsx)("p",{className:"mt-3 text-sm text-white/70",children:e.description})]},e.title))})]})}var E=s(2265);let k=(e,a,s)=>{e&&"function"==typeof e.animate&&e.animate(a,s)};function R(){return(0,E.useEffect)(()=>{let e=Array.from(document.querySelectorAll(".nav-links a")),a=Array.from(document.querySelectorAll(".anime-btn")),s=Array.from(document.querySelectorAll(".hero-roller-track .metric-card")),t=e=>{k(e.currentTarget,[{transform:"scale(1)"},{transform:"scale(1.06)"}],{duration:180,easing:"ease-out",fill:"forwards"})},i=e=>{k(e.currentTarget,[{transform:"scale(1.06)"},{transform:"scale(1)"}],{duration:180,easing:"ease-out",fill:"forwards"})},n=e=>{k(e.currentTarget,[{transform:"scale(1)"},{transform:"scale(0.96)"},{transform:"scale(1.02)"},{transform:"scale(1)"}],{duration:260,easing:"ease-in-out"})},r=e=>{k(e.currentTarget,[{transform:"translateY(0) scale(1)"},{transform:"translateY(-6px) scale(1.02)"}],{duration:220,easing:"ease-out",fill:"forwards"})},l=e=>{k(e.currentTarget,[{transform:"translateY(-6px) scale(1.02)"},{transform:"translateY(0) scale(1)"}],{duration:220,easing:"ease-out",fill:"forwards"})};return e.forEach(e=>{e.addEventListener("mouseenter",t),e.addEventListener("mouseleave",i)}),a.forEach(e=>{e.addEventListener("click",n)}),s.forEach(e=>{e.addEventListener("mouseenter",r),e.addEventListener("mouseleave",l)}),()=>{e.forEach(e=>{e.removeEventListener("mouseenter",t),e.removeEventListener("mouseleave",i)}),a.forEach(e=>{e.removeEventListener("click",n)}),s.forEach(e=>{e.removeEventListener("mouseenter",r),e.removeEventListener("mouseleave",l)})}},[]),null}function L(){return(0,t.jsxs)("div",{className:"relative min-h-screen overflow-hidden",children:[(0,t.jsx)(R,{}),(0,t.jsx)(f,{}),(0,t.jsx)("div",{className:"tech-grid","aria-hidden":"true"}),(0,t.jsxs)("main",{children:[(0,t.jsx)(g,{}),(0,t.jsx)(N,{}),(0,t.jsx)(y,{}),(0,t.jsx)(j,{}),(0,t.jsx)(b,{}),(0,t.jsx)(w,{}),(0,t.jsx)(d,{}),(0,t.jsx)(m,{})]}),(0,t.jsx)(n,{})]})}function A(){return(0,t.jsx)(L,{})}}},function(e){e.O(0,[423,971,117,744],function(){return e(e.s=7834)}),_N_E=e.O()}]);